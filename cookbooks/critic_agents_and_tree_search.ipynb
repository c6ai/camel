{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APw8wDolb0L9"
   },
   "source": [
    "# Critic Agents and Tree Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLCfmNtRb-jR"
   },
   "source": [
    "You can also check this cookbook in colab [here](https://colab.research.google.com/drive/1A2id3IyP1tSQXmtLsaY9-zyowSRzTaxk?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHQhWNnhcOch"
   },
   "source": [
    "## Philosophical Bits\n",
    "\n",
    "<!-- > *What magical trick makes us intelligent? The trick is that there is no trick. The power of intelligence stems from our vast diversity, not from any single, perfect principle.*\n",
    ">\n",
    "> -- Marvin Minsky, The Society of Mind, p. 308\n",
    "\n",
    "In this section, we will take a spite of the task-oriented `RolyPlaying()` class. We design this in an instruction-following manner. The essence is that to solve a complex task, you can enable two communicative agents collabratively working together step by step to reach solutions. The main concepts include:\n",
    "- **Task**: a task can be as simple as an idea, initialized by an inception prompt.\n",
    "- **AI User**: the agent who is expected to provide instructions.\n",
    "- **AI Assistant**: the agent who is expected to respond with solutions that fulfills the instructions. -->\n",
    "\n",
    "> **Prerequisite**: We assume that you have read the section on [intro to role-playing](https://colab.research.google.com/drive/1cmWPxXEsyMbmjPhD2bWfHuhd_Uz6FaJQ?usp=sharing).\n",
    "\n",
    "How do agents accomplish hard tasks? While reasoning can naturally emerge from next-token-prediction pretraining, it is still difficult for agents to solve complex tasks which require lots of intermediate steps. To tackle this issue, tree search is a simple and effective framework.\n",
    "\n",
    "A typical tree search include node expansion and node selection. In the [March 2023 paper](https://arxiv.org/abs/2303.17760), CAMEL introduces a heuristic tree search approach with critic in the loop, where the expansion and selection are presented below:\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://i.imgur.com/6x4ABpp.png\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "To put it simply, a critic agent is a helper agents in the role-playing session, which is capable of selecting proposals and provide informative verbal feedback to the role-playing agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUaGurDIVJBg"
   },
   "source": [
    "## Quick Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9NVFz-HVLXb"
   },
   "source": [
    "### 🕹 Step 0: Prepartions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtcC3c-KVZmU"
   },
   "outputs": [],
   "source": [
    "%pip install \"camel-ai==0.2.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CmgKGeCxVON-"
   },
   "outputs": [],
   "source": [
    "from camel.agents import CriticAgent\n",
    "from camel.generators import SystemMessageGenerator as sys_msg_gen\n",
    "from camel.messages import BaseMessage as bm\n",
    "from camel.types import RoleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyTTCe3IR_Lr"
   },
   "source": [
    "### Setting Up API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REqzgGL9SEaD"
   },
   "source": [
    "You'll need to set up your API keys for OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNBFEXc-R-0s",
    "outputId": "d6a21cfb-50b9-4a57-a40b-b3e44d95f287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your API key: ··········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Prompt for the API key securely\n",
    "openai_api_key = getpass('Enter your API key: ')\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcetZrjEcyo_"
   },
   "source": [
    "### 🕹 Step 1: Configure the Specifications for Critic Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "i-pIc9eTc0SH"
   },
   "outputs": [],
   "source": [
    "# Set the role name and the task\n",
    "critic_role = 'a picky critic'\n",
    "\n",
    "# Create the meta_dict and the role_tuple\n",
    "meta_dict = dict(critic_role=critic_role,\n",
    "                 criteria='Help better accomplish the task.')\n",
    "\n",
    "# Create the role tuple\n",
    "role_tuple = (critic_role, RoleType.CRITIC)\n",
    "\n",
    "# Generate the system message\n",
    "sys_msg = sys_msg_gen().from_dict(meta_dict=meta_dict,\n",
    "                                  role_tuple=role_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEUEpNa_c8sS"
   },
   "source": [
    "### 🕹 Step 2: Get the Critic Agents\n",
    "With the above arguments, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VetPjL70c9be"
   },
   "outputs": [],
   "source": [
    "critic_agent = CriticAgent(system_message=sys_msg,\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6aDvI1qc_kH"
   },
   "source": [
    "Let's take a look on the default system message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hP3hxdBKezD2",
    "outputId": "f057038b-8c12-4795-b4e8-9afb75c6a8cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a a picky critic who teams up with a {user_role} and a {assistant_role} to solve a task: {task}.\n",
      "Your job is to select an option from their proposals and provides your explanations.\n",
      "Your selection criteria are Help better accomplish the task..\n",
      "You always have to choose an option from the proposals.\n"
     ]
    }
   ],
   "source": [
    "print(critic_agent.system_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uO0Wo6Oe1Ul"
   },
   "source": [
    "You may overwrite the system message and configure the critic differently based on your own needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXzNaWp9dCvo"
   },
   "source": [
    "### 🕹 Step 3: Using Critic Agents for Task Solving\n",
    "Our `RolePlaying()` class provide a simple way for you to add the critic in the loop. Below we provide a basic pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ts52u_UVdDJA"
   },
   "outputs": [],
   "source": [
    "# Import necessary classes\n",
    "from camel.societies import RolePlaying\n",
    "from camel.configs import ChatGPTConfig\n",
    "from camel.types import TaskType, ModelType, ModelPlatformType\n",
    "from colorama import Fore\n",
    "from camel.utils import print_text_animated\n",
    "from camel.models import ModelFactory\n",
    "\n",
    "# Set the LLM model type and model config\n",
    "model_platform = ModelPlatformType.OPENAI\n",
    "model_type = ModelType.GPT_4O_MINI\n",
    "model_config = ChatGPTConfig(\n",
    "    temperature=0.8,  # the sampling temperature; the higher the more random\n",
    "    n=3,              # the no. of completion choices to generate for each input\n",
    "    )\n",
    "\n",
    "# Create the backend model\n",
    "model = ModelFactory.create(\n",
    "    model_platform=model_platform,\n",
    "    model_type=model_type,\n",
    "    model_config_dict=model_config.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlHF6LkRdFLo"
   },
   "source": [
    "We then need to set the kwargs for the task and each agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6hKpSzssdGvc"
   },
   "outputs": [],
   "source": [
    "task_kwargs = {\n",
    "    'task_prompt': 'Develop a plan to TRAVEL TO THE PAST and make changes.',\n",
    "    'with_task_specify': True,\n",
    "    'task_specify_agent_kwargs': {'model': model}\n",
    "}\n",
    "\n",
    "user_role_kwargs = {\n",
    "    'user_role_name': 'an ambitious aspiring TIME TRAVELER',\n",
    "    'user_agent_kwargs': {'model': model}\n",
    "}\n",
    "\n",
    "assistant_role_kwargs = {\n",
    "    'assistant_role_name': 'the best-ever experimental physicist',\n",
    "    'assistant_agent_kwargs': {'model': model}\n",
    "}\n",
    "\n",
    "critic_role_kwargs = {\n",
    "    'with_critic_in_the_loop': True,\n",
    "    'critic_criteria': 'improve the task performance',\n",
    "    'critic_kwargs': dict(verbose=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVpBAKZjfQ2Z"
   },
   "source": [
    "Putting them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7P73ky_fRWm",
    "outputId": "ff85c6de-43fe-404a-97d0-c9207575a46e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:camel.agents.chat_agent:Multiple messages returned in `step()`, message won't be recorded automatically. Please call `record_message()` to record the selected message manually.\n"
     ]
    }
   ],
   "source": [
    "society = RolePlaying(\n",
    "    **task_kwargs,             # The task arguments\n",
    "    **user_role_kwargs,        # The instruction sender's arguments\n",
    "    **assistant_role_kwargs,   # The instruction receiver's arguments\n",
    "    **critic_role_kwargs,      # The critic's arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Q-iBdzCfWOM"
   },
   "source": [
    "And the helper functions to run our society:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XBsQTzZofXvi"
   },
   "outputs": [],
   "source": [
    "def is_terminated(response):\n",
    "    \"\"\"\n",
    "    Give alerts when the session shuold be terminated.\n",
    "    \"\"\"\n",
    "    if response.terminated:\n",
    "        role = response.msg.role_type.name\n",
    "        reason = response.info['termination_reasons']\n",
    "        print(f'AI {role} terminated due to {reason}')\n",
    "\n",
    "    return response.terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jqlKDNUwfcfp"
   },
   "outputs": [],
   "source": [
    "def run(society, round_limit: int=10):\n",
    "\n",
    "    # Get the initial message from the ai assistant to the ai user\n",
    "    input_msg = society.init_chat()\n",
    "\n",
    "    # Starting the interactive session\n",
    "    for _ in range(round_limit):\n",
    "\n",
    "        # Get the both responses for this round\n",
    "        assistant_response, user_response = society.step(input_msg)\n",
    "\n",
    "        # Check the termination condition\n",
    "        if is_terminated(assistant_response) or is_terminated(user_response):\n",
    "            break\n",
    "\n",
    "        # Get the results\n",
    "        print(f'[AI User] {user_response.msg.content}.\\n')\n",
    "        print(f'[AI Assistant] {assistant_response.msg.content}.\\n')\n",
    "\n",
    "        # Check if the task is end\n",
    "        if 'CAMEL_TASK_DONE' in user_response.msg.content:\n",
    "            break\n",
    "\n",
    "        # Get the input message for the next round\n",
    "        input_msg = assistant_response.msg\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaiQJLt7ffKy"
   },
   "source": [
    "Now let's set our code in motion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSSF_RsPffjh"
   },
   "outputs": [],
   "source": [
    "run(society)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8e1bo7sHfkEo"
   },
   "source": [
    "In this setting, the `AI User` and `AI Assistant` will generate different options when responding (you can simply change the `temperature` in `model_config` to somewhat control the diversity). `AI Critic` will respond with its option selection and reasoning; such additional context will be fed to the two other agents and help them form better subsequent responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4YaF8I7fmOt"
   },
   "source": [
    "## Remarks\n",
    "While we see some performance gains from critic-in-the-loop, it may not really solve the fundamental extrapolation problem (and [self-consistency](https://arxiv.org/abs/2203.11171) remains a strong baseline for many tasks). It is debatable if those agents can extrapolate by self-play within its current scale. A more practical question is how we may *efficiently* introduce *informative* feedbacks/rewards, when agents are connected with external environments and are endowed with tools and memories. They are expected to have a good world model and know how to make abstraction and analogy when necessary. Stay tuned for our next update."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
