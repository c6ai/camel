
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Models &#8212; CAMEL 0.2.1a documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=89724694"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'key_modules/models';</script>
    <link rel="icon" href="https://raw.githubusercontent.com/camel-ai/camel/master/misc/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Message" href="messages.html" />
    <link rel="prev" title="Critic Agents and Tree Search" href="../cookbooks/critic_agents_and_tree_search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="https://raw.githubusercontent.com/camel-ai/camel/master/misc/primary_logo.png" class="logo__image only-light" alt=""/>
    <script>document.write(`<img src="https://raw.githubusercontent.com/camel-ai/camel/master/misc/primary_logo.png" class="logo__image only-dark" alt=""/>`);</script>
  
  
    <p class="title logo__title">CAMEL 0.2.1a</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get_started/setup.html">Installation and Setup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Agents</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/create_your_first_agent.html">Creating Your First Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/create_your_first_agents_society.html">Creating Your First Agent Society</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/embodied_agents.html">Embodied Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/critic_agents_and_tree_search.html">Critic Agents and Tree Search</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Key Modules</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="messages.html">Message</a></li>
<li class="toctree-l1"><a class="reference internal" href="memory.html">Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="prompts.html">Prompt</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks.html">Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="storages.html">Storages</a></li>
<li class="toctree-l1"><a class="reference internal" href="embeddings.html">Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="retrievers.html">Retrievers</a></li>
<li class="toctree-l1"><a class="reference internal" href="workforce.html">Workforce</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Cookbooks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/create_your_first_agent.html">Creating Your First Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/create_your_first_agents_society.html">Creating Your First Agent Society</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_society.html">Society Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_message.html">Message Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_with_tools.html">Tools Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_with_tools_from_Composio.html">Using Tools from Composio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_with_memory.html">Memory Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_with_rag.html">RAG Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_prompting.html">Prompting Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/task_generation.html">Task Generation Cookbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/knowledge_graph.html">Using CAMEL to Do Graph RAG with Mistral Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/roleplaying_scraper.html">Role-Playing <strong>Scraper</strong> for <strong>Report</strong> &amp; <strong>Knowledge Graph</strong> Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/video_analysis.html">Video Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/agents_tracking.html">Using AgentOps to Track CAMEL Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cookbooks/workforce_judge_committee.html">Create A Hackathon Judge Committee with Workforce</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../modules.html">camel</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../camel.html">camel package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../camel.agents.html">camel.agents package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../camel.agents.tool_agents.html">camel.agents.tool_agents package</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.configs.html">camel.configs package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.embeddings.html">camel.embeddings package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.interpreters.html">camel.interpreters package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.loaders.html">camel.loaders package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../camel.memories.html">camel.memories package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../camel.memories.blocks.html">camel.memories.blocks package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../camel.memories.context_creators.html">camel.memories.context_creators package</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.messages.html">camel.messages package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.models.html">camel.models package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.prompts.html">camel.prompts package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.responses.html">camel.responses package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.retrievers.html">camel.retrievers package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.societies.html">camel.societies package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../camel.storages.html">camel.storages package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../camel.storages.graph_storages.html">camel.storages.graph_storages package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../camel.storages.key_value_storages.html">camel.storages.key_value_storages package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../camel.storages.object_storages.html">camel.storages.object_storages package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../camel.storages.vectordb_storages.html">camel.storages.vectordb_storages package</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.tasks.html">camel.tasks package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.terminators.html">camel.terminators package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.toolkits.html">camel.toolkits package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.types.html">camel.types package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.utils.html">camel.utils package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.workforce.html">camel.workforce package</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/key_modules/models.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concept">1. Concept</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supported-model-platforms">2. Supported Model Platforms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-calling-template">3. Model Calling Template</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-source-llms">4. Open Source LLMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-ollama-to-set-llama-3-locally">4.1 Using Ollama to Set Llama 3 Locally</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-vllm-to-set-phi-3-locally">4.2 Using vLLM to Set Phi-3 Locally</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">5. Conclusion</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="models">
<h1>Models<a class="headerlink" href="#models" title="Link to this heading">#</a></h1>
<section id="concept">
<h2>1. Concept<a class="headerlink" href="#concept" title="Link to this heading">#</a></h2>
<p>The model is the brain of the intelligent agent, responsible for processing all input and output data. By calling different models, the agent can execute operations such as text analysis, image recognition, or complex reasoning according to task requirements. CAMEL offers a range of standard and customizable interfaces, as well as seamless integrations with various components, to facilitate the development of applications with Large Language Models (LLMs). In this part, we will introduce models currently supported by CAMEL and the working principles and interaction methods with models. All the codes are also available on colab notebook <a class="reference external" href="https://colab.research.google.com/drive/18hQLpte6WW2Ja3Yfj09NRiVY-6S2MFu7?usp=sharing">here</a>.</p>
</section>
<section id="supported-model-platforms">
<h2>2. Supported Model Platforms<a class="headerlink" href="#supported-model-platforms" title="Link to this heading">#</a></h2>
<p>The following table lists currently supported model platforms by CAMEL.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Model Platform</p></th>
<th class="head"><p>Available Models</p></th>
<th class="head"><p>Multi-modality</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>OpenAI</p></td>
<td><p>gpt-4o</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>OpenAI</p></td>
<td><p>gpt-4o-mini</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>OpenAI</p></td>
<td><p>o1-preview</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>OpenAI</p></td>
<td><p>o1-mini</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>OpenAI</p></td>
<td><p>gpt-4-turbo</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>OpenAI</p></td>
<td><p>gpt-4</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>OpenAI</p></td>
<td><p>gpt-3.5-turbo</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Azure OpenAI</p></td>
<td><p>gpt-4o</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Azure OpenAI</p></td>
<td><p>gpt-4-turbo</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Azure OpenAI</p></td>
<td><p>gpt-4</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Azure OpenAI</p></td>
<td><p>gpt-3.5-turbo</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Mistral AI</p></td>
<td><p>mistral-large-2</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Mistral AI</p></td>
<td><p>open-mistral-nemo</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Mistral AI</p></td>
<td><p>codestral</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Mistral AI</p></td>
<td><p>open-mistral-7b</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Mistral AI</p></td>
<td><p>open-mixtral-8x7b</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Mistral AI</p></td>
<td><p>open-mixtral-8x22b</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Mistral AI</p></td>
<td><p>open-codestral-mamba</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Anthropic</p></td>
<td><p>claude-3-5-sonnet-20240620</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Anthropic</p></td>
<td><p>claude-3-haiku-20240307</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Anthropic</p></td>
<td><p>claude-3-sonnet-20240229</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Anthropic</p></td>
<td><p>claude-3-opus-20240229</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Anthropic</p></td>
<td><p>claude-2.0</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Gemini</p></td>
<td><p>gemini-1.5-pro</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Gemini</p></td>
<td><p>ggemini-1.5-flash</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>ZhipuAI</p></td>
<td><p>glm-4v</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>ZhipuAI</p></td>
<td><p>glm-4</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>ZhipuAI</p></td>
<td><p>glm-3-turbo</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Reka</p></td>
<td><p>reka-core</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Reka</p></td>
<td><p>reka-flash</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Reka</p></td>
<td><p>reka-edge</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Nividia</p></td>
<td><p>nemotron-4-340b-reward</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>SambaNova</p></td>
<td><p>https://community.sambanova.ai/t/supported-models/193</p></td>
<td><p>—–</p></td>
</tr>
<tr class="row-odd"><td><p>Groq</p></td>
<td><p>https://console.groq.com/docs/models</p></td>
<td><p>—–</p></td>
</tr>
<tr class="row-even"><td><p>Ollama</p></td>
<td><p>https://ollama.com/library</p></td>
<td><p>—–</p></td>
</tr>
<tr class="row-odd"><td><p>vLLM</p></td>
<td><p>https://docs.vllm.ai/en/latest/models/supported_models.html</p></td>
<td><p>—–</p></td>
</tr>
<tr class="row-even"><td><p>Together AI</p></td>
<td><p>https://docs.together.ai/docs/chat-models</p></td>
<td><p>—–</p></td>
</tr>
<tr class="row-odd"><td><p>LiteLLM</p></td>
<td><p>https://docs.litellm.ai/docs/providers</p></td>
<td><p>—–</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="model-calling-template">
<h2>3. Model Calling Template<a class="headerlink" href="#model-calling-template" title="Link to this heading">#</a></h2>
<p>Here is the example code to use a chosen model. To utilize a different model, you can simply change three parameters the define your model to be used: <code class="docutils literal notranslate"><span class="pre">model_platform</span></code>, <code class="docutils literal notranslate"><span class="pre">model_type</span></code>, <code class="docutils literal notranslate"><span class="pre">model_config_dict</span></code> .</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">camel.models</span> <span class="kn">import</span> <span class="n">ModelFactory</span>
<span class="kn">from</span> <span class="nn">camel.types</span> <span class="kn">import</span> <span class="n">ModelPlatformType</span><span class="p">,</span> <span class="n">ModelType</span>
<span class="kn">from</span> <span class="nn">camel.configs</span> <span class="kn">import</span> <span class="n">ChatGPTConfig</span>
<span class="kn">from</span> <span class="nn">camel.messages</span> <span class="kn">import</span> <span class="n">BaseMessage</span>
<span class="kn">from</span> <span class="nn">camel.agents</span> <span class="kn">import</span> <span class="n">ChatAgent</span>

<span class="c1"># Define the model, here in this case we use gpt-4o-mini</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ModelFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model_platform</span><span class="o">=</span><span class="n">ModelPlatformType</span><span class="o">.</span><span class="n">OPENAI</span><span class="p">,</span>
    <span class="n">model_type</span><span class="o">=</span><span class="n">ModelType</span><span class="o">.</span><span class="n">GPT_4O_MINI</span><span class="p">,</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="n">ChatGPTConfig</span><span class="p">()</span><span class="o">.</span><span class="n">as_dict</span><span class="p">(),</span>
<span class="p">)</span>

<span class="c1"># Define an assitant message</span>
<span class="n">system_msg</span> <span class="o">=</span> <span class="n">BaseMessage</span><span class="o">.</span><span class="n">make_assistant_message</span><span class="p">(</span>
        <span class="n">role_name</span><span class="o">=</span><span class="s2">&quot;Assistant&quot;</span><span class="p">,</span>
        <span class="n">content</span><span class="o">=</span><span class="s2">&quot;You are a helpful assistant.&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Initialize the agent</span>
<span class="n">ChatAgent</span><span class="p">(</span><span class="n">system_msg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="open-source-llms">
<h2>4. Open Source LLMs<a class="headerlink" href="#open-source-llms" title="Link to this heading">#</a></h2>
<p>In the current landscape, for those seeking highly stable content generation, OpenAI’s gpt-4o-mini, gpt-4o are often recommended. However, the field is rich with many other outstanding open-source models that also yield commendable results. CAMEL can support developers to delve into integrating these open-source large language models (LLMs) to achieve project outputs based on unique input ideas.</p>
<p>While proprietary models like gpt-4o-mini and gpt-4o have set high standards for content generation, open-source alternatives offer viable solutions for experimentation and practical use. These models, supported by active communities and continuous improvements, provide flexibility and cost-effectiveness for developers and researchers.</p>
<section id="using-ollama-to-set-llama-3-locally">
<h3>4.1 Using Ollama to Set Llama 3 Locally<a class="headerlink" href="#using-ollama-to-set-llama-3-locally" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Download <a class="reference external" href="https://ollama.com/download">Ollama</a>.</p></li>
<li><p>After setting up Ollama, pull the Llama3 model by typing the following command into the terminal:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ollama<span class="w"> </span>pull<span class="w"> </span>llama3
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Create a <code class="docutils literal notranslate"><span class="pre">ModelFile</span></code> similar the one below in your project directory.</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">FROM</span> <span class="n">llama3</span>

<span class="c1"># Set parameters</span>
<span class="n">PARAMETER</span> <span class="n">temperature</span> <span class="mf">0.8</span>
<span class="n">PARAMETER</span> <span class="n">stop</span> <span class="n">Result</span>

<span class="c1"># Sets a custom system message to specify the behavior of the chat assistant</span>
<span class="c1"># Leaving it blank for now.</span>

<span class="n">SYSTEM</span> <span class="s2">&quot;&quot;&quot; &quot;&quot;&quot;</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Create a script to get the base model (llama3) and create a custom model using the <code class="docutils literal notranslate"><span class="pre">ModelFile</span></code> above. Save this as a <code class="docutils literal notranslate"><span class="pre">.sh</span></code> file:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/zsh

# variables
model_name=&quot;llama3&quot;
custom_model_name=&quot;camel-llama3&quot;

#get the base model
ollama pull $model_name

#create the model file
ollama create $custom_model_name -f ./Llama3ModelFile
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>Navigate to the directory where the script and <code class="docutils literal notranslate"><span class="pre">ModelFile</span></code> are located and run the script. Enjoy your Llama3 model, enhanced by CAMEL’s excellent agents.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">camel.agents</span> <span class="kn">import</span> <span class="n">ChatAgent</span>
<span class="kn">from</span> <span class="nn">camel.messages</span> <span class="kn">import</span> <span class="n">BaseMessage</span>
<span class="kn">from</span> <span class="nn">camel.models</span> <span class="kn">import</span> <span class="n">ModelFactory</span>
<span class="kn">from</span> <span class="nn">camel.types</span> <span class="kn">import</span> <span class="n">ModelPlatformType</span>

<span class="n">ollama_model</span> <span class="o">=</span> <span class="n">ModelFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model_platform</span><span class="o">=</span><span class="n">ModelPlatformType</span><span class="o">.</span><span class="n">OLLAMA</span><span class="p">,</span>
    <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;llama3&quot;</span><span class="p">,</span>
    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;http://localhost:11434/v1&quot;</span><span class="p">,</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">},</span>
<span class="p">)</span>

<span class="n">assistant_sys_msg</span> <span class="o">=</span> <span class="n">BaseMessage</span><span class="o">.</span><span class="n">make_assistant_message</span><span class="p">(</span>
    <span class="n">role_name</span><span class="o">=</span><span class="s2">&quot;Assistant&quot;</span><span class="p">,</span>
    <span class="n">content</span><span class="o">=</span><span class="s2">&quot;You are a helpful assistant.&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ChatAgent</span><span class="p">(</span><span class="n">assistant_sys_msg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">ollama_model</span><span class="p">,</span> <span class="n">token_limit</span><span class="o">=</span><span class="mi">4096</span><span class="p">)</span>

<span class="n">user_msg</span> <span class="o">=</span> <span class="n">BaseMessage</span><span class="o">.</span><span class="n">make_user_message</span><span class="p">(</span>
    <span class="n">role_name</span><span class="o">=</span><span class="s2">&quot;User&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="s2">&quot;Say hi to CAMEL&quot;</span>
<span class="p">)</span>
<span class="n">assistant_response</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">user_msg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assistant_response</span><span class="o">.</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="using-vllm-to-set-phi-3-locally">
<h3>4.2 Using vLLM to Set Phi-3 Locally<a class="headerlink" href="#using-vllm-to-set-phi-3-locally" title="Link to this heading">#</a></h3>
<p>Install <a class="reference external" href="https://docs.vllm.ai/en/latest/getting_started/installation.html">vLLM</a> first.</p>
<p>After setting up vLLM, start an OpenAI compatible server for example by:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">vllm</span><span class="o">.</span><span class="n">entrypoints</span><span class="o">.</span><span class="n">openai</span><span class="o">.</span><span class="n">api_server</span> <span class="o">--</span><span class="n">model</span> <span class="n">microsoft</span><span class="o">/</span><span class="n">Phi</span><span class="o">-</span><span class="mi">3</span><span class="o">-</span><span class="n">mini</span><span class="o">-</span><span class="mi">4</span><span class="n">k</span><span class="o">-</span><span class="n">instruct</span> <span class="o">--</span><span class="n">api</span><span class="o">-</span><span class="n">key</span> <span class="n">vllm</span> <span class="o">--</span><span class="n">dtype</span> <span class="n">bfloat16</span>
</pre></div>
</div>
<p>Create and run following script (more details please refer to this <a class="reference external" href="https://github.com/camel-ai/camel/blob/master/examples/models/vllm_model_example.py">example</a>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">camel.agents</span> <span class="kn">import</span> <span class="n">ChatAgent</span>
<span class="kn">from</span> <span class="nn">camel.messages</span> <span class="kn">import</span> <span class="n">BaseMessage</span>
<span class="kn">from</span> <span class="nn">camel.models</span> <span class="kn">import</span> <span class="n">ModelFactory</span>
<span class="kn">from</span> <span class="nn">camel.types</span> <span class="kn">import</span> <span class="n">ModelPlatformType</span>

<span class="n">vllm_model</span> <span class="o">=</span> <span class="n">ModelFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model_platform</span><span class="o">=</span><span class="n">ModelPlatformType</span><span class="o">.</span><span class="n">VLLM</span><span class="p">,</span>
    <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;microsoft/Phi-3-mini-4k-instruct&quot;</span><span class="p">,</span>
    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;http://localhost:8000/v1&quot;</span><span class="p">,</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">},</span>
    <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;vllm&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">assistant_sys_msg</span> <span class="o">=</span> <span class="n">BaseMessage</span><span class="o">.</span><span class="n">make_assistant_message</span><span class="p">(</span>
    <span class="n">role_name</span><span class="o">=</span><span class="s2">&quot;Assistant&quot;</span><span class="p">,</span>
    <span class="n">content</span><span class="o">=</span><span class="s2">&quot;You are a helpful assistant.&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">ChatAgent</span><span class="p">(</span><span class="n">assistant_sys_msg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">vllm_model</span><span class="p">,</span> <span class="n">token_limit</span><span class="o">=</span><span class="mi">4096</span><span class="p">)</span>

<span class="n">user_msg</span> <span class="o">=</span> <span class="n">BaseMessage</span><span class="o">.</span><span class="n">make_user_message</span><span class="p">(</span>
    <span class="n">role_name</span><span class="o">=</span><span class="s2">&quot;User&quot;</span><span class="p">,</span>
    <span class="n">content</span><span class="o">=</span><span class="s2">&quot;Say hi to CAMEL AI&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">assistant_response</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">user_msg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assistant_response</span><span class="o">.</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="conclusion">
<h2>5. Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>In conclusion, CAMEL empowers developers to explore and integrate these diverse models, unlocking new possibilities for innovative AI applications. The world of large language models offers a rich tapestry of options beyond just the well-known proprietary solutions. By guiding users through model selection, environment setup, and integration, CAMEL bridges the gap between cutting-edge AI research and practical implementation. Its hybrid approach, combining in-house implementations with third-party integrations, offers unparalleled flexibility and comprehensive support for LLM-based development. Don’t just watch this transformation that is happening from the sidelines.</p>
<p>Dive into the CAMEL documentation, experiment with different models, and be part of shaping the future of AI. The era of truly flexible and powerful AI is here - are you ready to make your mark?</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../cookbooks/critic_agents_and_tree_search.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Critic Agents and Tree Search</p>
      </div>
    </a>
    <a class="right-next"
       href="messages.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Message</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concept">1. Concept</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supported-model-platforms">2. Supported Model Platforms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-calling-template">3. Model Calling Template</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-source-llms">4. Open Source LLMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-ollama-to-set-llama-3-locally">4.1 Using Ollama to Set Llama 3 Locally</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-vllm-to-set-phi-3-locally">4.2 Using vLLM to Set Phi-3 Locally</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">5. Conclusion</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By CAMEL-AI.org
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, CAMEL-AI.org.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>